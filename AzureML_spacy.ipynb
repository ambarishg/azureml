{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27.0\n"
     ]
    }
   ],
   "source": [
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n",
      "Interactive authentication successfully completed.\n",
      "Deploying StorageAccount with name azuremlwstorage84e2b186e.\n",
      "Deploying AppInsights with name azuremlwinsightscb75c22b.\n",
      "Deployed AppInsights with name azuremlwinsightscb75c22b. Took 8.52 seconds.\n",
      "Deploying KeyVault with name azuremlwkeyvault0fd0acb0.\n",
      "Deployed KeyVault with name azuremlwkeyvault0fd0acb0. Took 25.55 seconds.\n",
      "Deployed StorageAccount with name azuremlwstorage84e2b186e. Took 34.13 seconds.\n",
      "Deploying Workspace with name azureml_workspace2.\n",
      "Deployed Workspace with name azureml_workspace2. Took 34.31 seconds.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\r\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
    "\r\n",
    "sid = '<subscription id>'\r\n",
    "tenant_id = '<tenant id>'\r\n",
    "\r\n",
    "forced_interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id, force=True)\r\n",
    "\r\n",
    "ws = Workspace.create(name='azureml_workspace2',\r\n",
    "            subscription_id= sid, \r\n",
    "            resource_group='rgazureml',\r\n",
    "            create_resource_group = True,\r\n",
    "            location='centralus'\r\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Default Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ./recodata\\professionals.csv\n",
      "Uploaded ./recodata\\professionals.csv, 1 files out of an estimated total of 3\n",
      "Uploading ./recodata\\questions.csv\n",
      "Uploaded ./recodata\\questions.csv, 2 files out of an estimated total of 3\n",
      "Uploading ./recodata\\answers.csv\n",
      "Uploaded ./recodata\\answers.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#upload data by using get_default_datastore()\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./recodata', target_path='recodata', overwrite=True, show_progress=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create the folder\n",
    "folder_training_script = './recocode'\n",
    "os.makedirs(folder_training_script, exist_ok=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute target created\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# Step 1: name the cluster and set the minimal and maximal number of nodes \n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpucluster\")\n",
    "min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 1)\n",
    "\n",
    "# Step 2: choose environment variables \n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "provisioning_config = AmlCompute.provisioning_configuration(\n",
    "    vm_size = vm_size, min_nodes = min_nodes, max_nodes = max_nodes)\n",
    "\n",
    "# create the cluster\n",
    "compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "print('Compute target created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./recocode/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_training_script/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gc\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import pickle\n",
    "import spacy\n",
    "from spacy.cli.download import download as spacy_download\n",
    "\n",
    "from azureml.core import Run\n",
    "# from utils import load_data\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase,remove punctuation\n",
    "    .'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'recodata')\n",
    "print('Data folder:', data_folder)\n",
    "\n",
    "questions  = pd.read_csv(os.path.join(data_folder, 'questions.csv'))\n",
    "professionals = pd.read_csv(os.path.join(data_folder, 'professionals.csv'))\n",
    "answers = pd.read_csv(os.path.join(data_folder, 'answers.csv'))\n",
    "\n",
    "prof_ans = pd.merge(professionals, answers, how = 'left' ,\n",
    "                    left_on = 'professionals_id', right_on = 'answers_author_id')\n",
    "prof_ans_q = pd.merge(prof_ans, questions, how = 'left' ,\n",
    "                      left_on = 'answers_question_id', right_on = 'questions_id')\n",
    "\n",
    "prof_ans_q = prof_ans_q[(~prof_ans_q[\"questions_title\"].isna()) | (~prof_ans_q[\"questions_body\"].isna()) ]\n",
    "\n",
    "q = prof_ans_q[\"questions_title\"] + \" \" + prof_ans_q[\"questions_body\"]\n",
    "q  = q.apply(lambda x:clean_text(x))\n",
    "\n",
    "spacy_download('en')\n",
    "spacy_download('en_core_web_lg')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "spacy_questions = [nlp(q1).vector for q1 in q ]\n",
    "pickle.dump(spacy_questions,open(\"outputs/spacy_questions.pkl\",\"wb\"))\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.core.environment:'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reco-env defined.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "wine_env = Environment(\"reco-env\")\n",
    "wine_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "wine_env.docker.enabled = False # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies (conda or pip as required)\n",
    "wine_packages = CondaDependencies.create(conda_packages = ['scikit-learn','spacy'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "wine_env.python.conda_dependencies = wine_packages\n",
    "\n",
    "print(wine_env.name, 'defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the environment in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"reco-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.27.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"spacy\"\n",
       "            ],\n",
       "            \"name\": \"azureml_44d5703ab7e06ef99f267010608dcead\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"2\"\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the environment\n",
    "wine_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount()\n",
    "}\n",
    "\n",
    "registered_env = Environment.get(ws, 'reco-env')\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=folder_training_script,\n",
    "                      script_params=script_params,\n",
    "                      compute_target = compute_target, # Run the experiment on the remote compute target\n",
    "                      environment_definition = registered_env,\n",
    "                      entry_script='train.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "#Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = \"reco_expt\")\n",
    "\n",
    "print('Experiment created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit the Experiment with the Estimator information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>reco_expt</td><td>reco_expt_1620842844_99e76fd4</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/reco_expt_1620842844_99e76fd4?wsid=/subscriptions/6e05a726-0769-4103-aed1-e2ee3a907a5a/resourcegroups/rgazureml/workspaces/azureml_workspace2&amp;tid=0f942ca0-ebef-4f26-80f8-f501d599ba90\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: reco_expt,\n",
       "Id: reco_expt_1620842844_99e76fd4,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(config=estimator)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "#get the result\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy_questions_model\n"
     ]
    }
   ],
   "source": [
    "spacy_questions = run.register_model(model_name='spacy_questions_model',\n",
    "                           model_path='outputs/spacy_questions.pkl',\n",
    "                           tags = {'area': \"spacy_questions\", 'type': \"spacy\"},\n",
    "                           description = \"spacy_questions\")\n",
    "\n",
    "print(spacy_questions.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./recocode/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_training_script/score.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import spacy\n",
    "from spacy.cli.download import download as spacy_download\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model_path\n",
    "    global nlp\n",
    "    \n",
    "    # Get the path to the registered model file and load it\n",
    "    model_path = Model.get_model_path('spacy_questions_model')\n",
    "    spacy_download('en')\n",
    "    spacy_download('en_core_web_lg')\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    \n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = (json.loads(raw_data)['data'])\n",
    "    \n",
    "\n",
    "    with open(model_path, 'rb') as f:\n",
    "        spacy_questions = pickle.load(f)\n",
    "    \n",
    "    q_new = [nlp(data).vector]\n",
    "    result = cosine_similarity(q_new,spacy_questions)\n",
    "    predictions = result\n",
    "    \n",
    "    return predictions.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create the Dependencies for the Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in ./recocode/env.yml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Add the dependencies for your model\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"spacy\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = './recocode/env.yml'\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Inference Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              source_directory = './recocode',\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"env.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Inference Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating......................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'aks-cluster'\n",
    "compute_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Model to the Inference Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-13 00:59:06+05:30 Creating Container Registry if not exists.\n",
      "2021-05-13 00:59:06+05:30 Registering the environment.\n",
      "2021-05-13 00:59:08+05:30 Use the existing image.\n",
      "2021-05-13 00:59:10+05:30 Creating resources in AKS.\n",
      "2021-05-13 00:59:10+05:30 Submitting deployment to compute.\n",
      "2021-05-13 00:59:12+05:30 Checking the status of deployment reco-service3..\n",
      "2021-05-13 01:01:12+05:30 Checking the status of inference endpoint reco-service3.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model1 = ws.models['spacy_questions_model']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'reco-service3',\n",
    "                       models = [model1],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform predictions with the Inference Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://20.80.120.179:80/api/v1/service/reco-service3/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key, secondary_key = service.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ai4ob6rfQM4YCgZKzl4DL80EVcfYsL9J'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = \"I want to be a data scientist. What should I study\"\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { \"Content-Type\":\"application/json\",\n",
    "                    \"Authorization\":\"Bearer \" + primary_key }\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = endpoint,\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24223 30993 16339 30968 47722 33136 16221 18047 48865 49181]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = \"recodata\"\n",
    "\n",
    "questions  = pd.read_csv(os.path.join(data_folder, 'questions.csv'))\n",
    "professionals = pd.read_csv(os.path.join(data_folder, 'professionals.csv'))\n",
    "answers = pd.read_csv(os.path.join(data_folder, 'answers.csv'))\n",
    "\n",
    "prof_ans = pd.merge(professionals, answers, how = 'left' ,\n",
    "                    left_on = 'professionals_id', right_on = 'answers_author_id')\n",
    "prof_ans_q = pd.merge(prof_ans, questions, how = 'left' ,\n",
    "                      left_on = 'answers_question_id', right_on = 'questions_id')\n",
    "\n",
    "prof_ans_q = prof_ans_q[(~prof_ans_q[\"questions_title\"].isna()) | (~prof_ans_q[\"questions_body\"].isna()) ]\n",
    "\n",
    "index = np.argsort(result)[:,-10:]\n",
    "print(index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>You should search for Algorithm videos. Usually when studying data, you would need to know about databases structure, analytics skills, and some other logics. Another thing you could do would be start analyzing some small real cases like how long does it take to go from your house to the supermarket and what you could do to reduce the time? or how often do you drink water (time gap between each occurence). How could you track that? and how could you improve it? is it good?</p><p>these are a few examples on how you could analyze stuff.</p>'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_ans_q.iloc[index[0][-1]][\"answers_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p> </p><p>Hello Chong G.</p><p> </p><p>I am not a data scientist, but I think I can give you some advice on this. Nowadays, an increasing number of professions are requiring analytics capabilities.</p><p> </p><p> </p><p>There are some core things you should learn to handle great amount of data, like:</p><p>&nbsp;</p><p>Relational Database concepts;</p><p>SQL - Computer language for creating and managing databases;</p><p>Excel;</p><p>Programing languages such as C, VBA, R...&nbsp;</p><p><br></p><p>You should also consider learning how to display the data in an organized way and Power BI / Think-Cell are great for that</p><p>  </p><p>There are several tutorials around the internet about those topics and also focused courses. I personally recommend the latter, because it is easier to progress through the topics.</p><p><br></p><p>Hope my advice was helpful to you!</p><p> </p>'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_ans_q.iloc[index[0][-2]][\"answers_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>It is wonderful that you want to learn software coding and become a software engineer. This is  certainly a field that has and will continue to have lots of exciting prospects for learning and growth. One of the ways to become a software engineer is to get a degree in Computer Science or Information technology or computer applications. For applying to a college to study these disciplines one must first of all be interested in and study Maths as well as Physics and Chemistry (so called PCM subjects) till 12th standard. Meanwhile, in many schools, computers is taught as a subject in 9th, 10th, 11th and 12th standards. As part of the computer subject you will learn about programming and learn the basics of coding in a language such as Java. If your school/PUC college does not offer computers as a subject then you can enroll for a programming class outside school or if you have access to a computer you can learn programming on your own. Based on the above if you can give me more details I would be very happy to provide further inputs and guidance</p>'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_ans_q.iloc[index[0][-3]][\"answers_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63f1087d36cbe8f2eaa5a6e9bf8f00ad953864e3c527e5ac025ca4eb18c7d7e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}